version: '3.8'

services:
#  keycloak:
#    image: jboss/keycloak
#    container_name: keycloak
#    restart: always
#    environment:
#      KEYCLOAK_USER: admin
#      KEYCLOAK_PASSWORD: admin
#      DB_VENDOR: postgres
#      DB_ADDR: postgres
#      DB_DATABASE: keycloak
#      DB_USER: postgres
#      DB_PASSWORD: postgres
#      # volumes:
#      #   - ./config/realm-export.json:/opt/jboss/keycloak/realm-export.json
#      # command:
#      # - "-b 0.0.0.0"
#      # - "-Dkeycloak.import=/opt/jboss/keycloak/realm-export.json"
#      # - "-Dkeycloak.profile.feature.scripts=enabled"
#      # - "-Dkeycloak.profile.feature.upload_scripts=enabled"
#    ports:
#      - "8080:8080"
#    networks:
#      - flowing

  postgres:
    container_name: postgres
    image: postgres:latest
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: "postgres"
      POSTGRES_PASSWORD: "postgres"
    command:
      # configuration for logging. All this config properties we can also set in postgres.conf.conf
      - "postgres"
      - "-c"
      - "log_statement=all"
      - "-c"
      - "log_directory=log"
      - "-c"
      - "log_filename=postgresql-%Y-%m-%d_%H%M%S.log"
      - "-c"
      - "logging_collector=on"
      - "-c"
      - "log_min_error_statement=error"
      - "-c"
      - "log_rotation_age=60"
    volumes:
      # If you need access to postgres data, uncomment this part
      # - pgdata:/var/lib/postgresql/data
      # - pgconf:/etc/postgresql
      # - pglog:/var/log/postgresql
      - ./config/postgres/init_scripts:/docker-entrypoint-initdb.d
    networks:
      - flowing
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U postgres" ]
      interval: 10s
      timeout: 5s
      retries: 5

  zookeeper:
    image: "confluentinc/cp-zookeeper:latest"
    container_name: zookeeper
    hostname: zookeeper
    networks:
      - flowing
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  kafka:
    image: "confluentinc/cp-kafka:latest"
    container_name: kafka
    hostname: kafka
    depends_on:
      - zookeeper
    networks:
      - flowing
    ports:
      - 9092:9092
      - 29092:29092
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_LISTENERS: PLAINTEXT://:9092,PLAINTEXT_HOST://:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  zeebe: # https://docs.camunda.io/docs/self-managed/platform-deployment/docker/#zeebe
    image: camunda/zeebe:${CAMUNDA_PLATFORM_VERSION:-8.0.2}
    container_name: zeebe
    ports:
      - "26500:26500"
      - "9600:9600"
    environment: # https://docs.camunda.io/docs/self-managed/zeebe-deployment/configuration/environment-variables/
      - ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_CLASSNAME=io.camunda.zeebe.exporter.ElasticsearchExporter
      - ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_URL=http://elasticsearch:9200
      - ZEEBE_BROKER_EXPORTERS_ELASTICSEARCH_ARGS_BULK_SIZE=1
      # allow running with low disk space
      - ZEEBE_BROKER_DATA_DISKUSAGECOMMANDWATERMARK=0.998
      - ZEEBE_BROKER_DATA_DISKUSAGEREPLICATIONWATERMARK=0.999
      - "JAVA_TOOL_OPTIONS=-Xms512m -Xmx512m"
    restart: always
    volumes:
      - zeebe:/usr/local/zeebe/data
    networks:
      - flowing
    depends_on:
      - elasticsearch

  operate: # https://docs.camunda.io/docs/self-managed/platform-deployment/docker/#operate
    image: camunda/operate:${CAMUNDA_PLATFORM_VERSION:-8.0.2}
    container_name: operate
    ports:
      - "8081:8080"
    environment: # https://docs.camunda.io/docs/self-managed/operate-deployment/configuration/
      - CAMUNDA_OPERATE_ZEEBE_GATEWAYADDRESS=zeebe:26500
      - CAMUNDA_OPERATE_ELASTICSEARCH_URL=http://elasticsearch:9200
      - CAMUNDA_OPERATE_ZEEBEELASTICSEARCH_URL=http://elasticsearch:9200
    networks:
      - flowing
    depends_on:
      - zeebe
      - elasticsearch

  elasticsearch: # https://hub.docker.com/_/elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:${ELASTIC_VERSION:-7.17.0}
    container_name: elasticsearch
    ports:
      - "9200:9200"
      - "9300:9300"
    environment:
      - bootstrap.memory_lock=true
      - discovery.type=single-node
      # allow running with low disk space
      - cluster.routing.allocation.disk.threshold_enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ulimits:
      memlock:
        soft: -1
        hard: -1
    restart: always
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200/_cat/health | grep -q green" ]
      interval: 30s
      timeout: 5s
      retries: 3
    volumes:
      - elastic:/usr/share/elasticsearch/data
    networks:
      - flowing

volumes:
  zeebe:
  elastic:

networks:
  flowing:
    external: true